{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 『2022 CCF BDCI』- 基于TrustAI的阅读理解可解释性评测基线\n",
    "## 1、项目介绍\n",
    "深度学习模型在很多NLP任务上已经取得巨大成功，但其常被当作一个黑盒使用，内部预测机制对使用者是不透明的。这使得深度学习模型结果不被使用者信任，增加了落地难度，尤其在医疗、法律等特殊领域。同时，当模型出现效果不好或鲁棒性差等问题时，由于不了解其内部机制，很难对模型进行改进优化。\n",
    "近期，深度学习模型的可解释性被越来越多的人关注。但模型的可解释性评估还不够完善，本基线提供了阅读理解任务的评测数据和相关评测指标，旨在评估模型的可解释性。\n",
    "近期百度发布了一款集可信分析和增强于一体的可信AI工具集TrustAI，旨在探索模型预测机制并增强模型效果。本次基线基于TrustAI搭建。\n",
    "## 2、基线运行\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依赖安装\n",
    "安装一些必须的依赖包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-10-10T11:26:23.796405Z",
     "iopub.status.busy": "2022-10-10T11:26:23.795364Z",
     "iopub.status.idle": "2022-10-10T11:26:24.136671Z",
     "shell.execute_reply": "2022-10-10T11:26:24.135507Z",
     "shell.execute_reply.started": "2022-10-10T11:26:23.796375Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/bin/pip3\", line 5, in <module>\n",
      "    from pip._internal.cli.main import main\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_internal/cli/main.py\", line 9, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_internal/cli/main_parser.py\", line 8, in <module>\n",
      "    from pip._internal.cli import cmdoptions\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_internal/cli/cmdoptions.py\", line 24, in <module>\n",
      "    from pip._internal.cli.parser import ConfigOptionParser\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_internal/cli/parser.py\", line 12, in <module>\n",
      "    from pip._internal.configuration import Configuration, ConfigurationError\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_internal/configuration.py\", line 20, in <module>\n",
      "    from pip._internal.exceptions import (\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_internal/exceptions.py\", line 13, in <module>\n",
      "    from pip._vendor.requests.models import Request, Response\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_vendor/requests/__init__.py\", line 43, in <module>\n",
      "    from pip._vendor import urllib3\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_vendor/urllib3/__init__.py\", line 11, in <module>\n",
      "    from . import exceptions\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_vendor/urllib3/exceptions.py\", line 3, in <module>\n",
      "    from .packages.six.moves.http_client import IncompleteRead as httplib_IncompleteRead\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_vendor/urllib3/packages/six.py\", line 192, in find_spec\n",
      "    return spec_from_loader(fullname, self)\n",
      "  File \"<frozen importlib._bootstrap>\", line 449, in spec_from_loader\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_vendor/urllib3/packages/six.py\", line 222, in is_package\n",
      "    return hasattr(self.__get_module(fullname), \"__path__\")\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_vendor/urllib3/packages/six.py\", line 121, in __getattr__\n",
      "    _module = self._resolve()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_vendor/urllib3/packages/six.py\", line 118, in _resolve\n",
      "    return _import_module(self.mod)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pip/_vendor/urllib3/packages/six.py\", line 87, in _import_module\n",
      "    __import__(name)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/http/client.py\", line 1356, in <module>\n",
      "    import ssl\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/ssl.py\", line 98, in <module>\n",
      "    import _ssl             # if we can't import it, let the error propagate\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# !mkdir /home/aistudio/external-libraries\n",
    "!pip3 install -U paddlepaddle-gpu==2.3.2 \n",
    "# !pip3 install -U paddlenlp==2.4.0 -t /home/aistudio/external-libraries\n",
    "# !pip3 install trustai==0.1.5 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备\n",
    "#### 1）模型训练数据\n",
    "我们推荐使用DuReader-robust数据集训练中文相似度计算模型。Paddlenlp框架会自动下载及缓存训练数据集，默认缓存存储路径为\"~/.paddlenlp/datasets\"。如需修改训练数据，请参考『初始化工作』中DATASET_NAME的修改。\n",
    "#### 2）下载预训练模型\n",
    "基线使用了ERNIE-3.0-base预训练模型。Paddlenlp框架自动缓存模型文件，默认缓存存储路径为\"~/.paddlenlp/models\"。如需修改依赖的预训练模型，请在『初始化工作』中修改MODEL_NAME。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化工作\n",
    "初始化工作包括了模型选择及加载、训练数据集选择、模型存储路径设定、抽取证据的长度占原文本长度的比例设定等。可按需更改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T13:55:36.196399Z",
     "iopub.status.busy": "2022-10-27T13:55:36.195054Z",
     "iopub.status.idle": "2022-10-27T13:55:38.146746Z",
     "shell.execute_reply": "2022-10-27T13:55:38.145884Z",
     "shell.execute_reply.started": "2022-10-27T13:55:36.196333Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n",
      "2.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-27 21:55:36,205] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh.pdparams\n",
      "[2022-10-27 21:55:38,109] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh_vocab.txt\n",
      "[2022-10-27 21:55:38,135] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json\n",
      "[2022-10-27 21:55:38,139] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "import json\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForQuestionAnswering, ErnieTokenizer\n",
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "from mrc_utils import *\n",
    "print(paddle.__version__)\n",
    "print(paddlenlp.__version__)\n",
    "# Select pre-trained model\n",
    "MODEL_NAME = \"ernie-3.0-base-zh\" # choose from [\"ernie-1.0\", \"ernie-1.0-base-zh\", \"ernie-1.0-large-zh-cw\", \"ernie-2.0-base-zh\", \"ernie-2.0-large-zh\", \"ernie-3.0-xbase-zh\", \"ernie-3.0-base-zh\", \"ernie-3.0-medium-zh\", \"ernie-3.0-mini-zh\", \"ernie-3.0-micro-zh\", \"ernie-3.0-nano-zh\"]\n",
    "# Select dataset for model training\n",
    "DATASET_NAME = 'dureader_robust'\n",
    "# Set the path to save the trained model\n",
    "MODEL_SAVE_PATH = f'save_model/{DATASET_NAME}-{MODEL_NAME}'\n",
    "# MODEL_SAVE_PATH = f'save_model/model_state.pdparams'\n",
    "RATIONALE_RATIO = 0.096 # 0.096 for Chinese dataset, 0.102 for English dataset\n",
    "\n",
    "# Init model and tokenizer\n",
    "model = ErnieForQuestionAnswering.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-10-10T13:35:25.214697Z",
     "iopub.status.busy": "2022-10-10T13:35:25.214088Z",
     "iopub.status.idle": "2022-10-10T13:35:29.784974Z",
     "shell.execute_reply": "2022-10-10T13:35:29.783817Z",
     "shell.execute_reply.started": "2022-10-10T13:35:25.214664Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 7407/20038 [00:04<00:07, 1659.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142/3130720434.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/datasets/dataset.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path_or_read_func, name, data_files, splits, lazy, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                     \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/datasets/dataset.py\u001b[0m in \u001b[0;36mread_datasets\u001b[0;34m(self, splits, data_files)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mnum_shards\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAn\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0mshards\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnum_shards\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtrainers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m                 \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAn\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/datasets/dureader_robust.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         if not os.path.exists(fullname) or (data_hash and\n\u001b[1;32m     54\u001b[0m                                             not md5file(fullname) == data_hash):\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mget_path_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMD5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/utils/download.py\u001b[0m in \u001b[0;36mget_path_from_url\u001b[0;34m(url, root_dir, md5sum, check_exist, decompress, method)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mParallelEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_endpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_endpoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mfullpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/utils/download.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(url, path, md5sum, method)\u001b[0m\n\u001b[1;32m    256\u001b[0m                                \"Retry limit reached\".format(url))\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_download_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/utils/download.py\u001b[0m in \u001b[0;36m_get_download\u001b[0;34m(url, fullname)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1023\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mmuch\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mper\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mmay\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mless\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mparticularly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mlikely\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0musing\u001b[0m \u001b[0mcompressed\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHowever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mwill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0mnever\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mfp_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "# Hyperparameters\n",
    "batch_size = 56\n",
    "max_seq_length = 512\n",
    "epochs = 1  #3\n",
    "warmup_proportion = 0.1\n",
    "weight_decay = 0.01\n",
    "doc_stride = 512\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Load dataset\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])\n",
    "\n",
    "# Start training\n",
    "training_mrc_model(model, \n",
    "                tokenizer,\n",
    "                train_ds, \n",
    "                dev_ds,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                learning_rate=learning_rate,\n",
    "                warmup_proportion=warmup_proportion,\n",
    "                max_seq_length=max_seq_length,\n",
    "                doc_stride=doc_stride, \n",
    "                weight_decay=weight_decay,\n",
    "                save_dir=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "这里以ERNIE-3.0为例训练一个阅读理解模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-10-06T14:14:50.260840Z",
     "iopub.status.busy": "2022-10-06T14:14:50.260246Z",
     "iopub.status.idle": "2022-10-06T14:14:58.496228Z",
     "shell.execute_reply": "2022-10-06T14:14:58.126119Z",
     "shell.execute_reply.started": "2022-10-06T14:14:50.260799Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20038/20038 [00:02<00:00, 8724.16it/s] \n",
      "Process ForkPoolWorker-13:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_179/1142161014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mdoc_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc_stride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 save_dir=MODEL_SAVE_PATH)\n\u001b[0m",
      "\u001b[0;32m~/mrc_utils.py\u001b[0m in \u001b[0;36mtraining_mrc_model\u001b[0;34m(model, tokenizer, train_ds, dev_ds, batch_size, epochs, learning_rate, warmup_proportion, max_seq_length, doc_stride, weight_decay, save_dir)\u001b[0m\n\u001b[1;32m    571\u001b[0m                             tokenizer=tokenizer)\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trans_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     dev_trans_func = partial(prepare_validation_features, \n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/datasets/dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, fn, lazy, batched, num_workers)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtransformed_shards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/datasets/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtransformed_shards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/datasets/dataset.py\", line 420, in _map\n",
      "    else:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/queues.py\", line 355, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/connection.py\", line 219, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aistudio/mrc_utils.py\", line 464, in prepare_train_features\n",
      "    return_dict=False)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/connection.py\", line 410, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils_base.py\", line 2252, in __call__\n",
      "    **kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/multiprocess/connection.py\", line 382, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils_base.py\", line 2458, in batch_encode\n",
      "    self,\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils.py\", line 1103, in _batch_encode_plus\n",
      "    kwargs['text_pairs'] = [\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils.py\", line 1069, in get_input_ids\n",
      "    else:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils.py\", line 749, in tokenize\n",
      "    for i, token in enumerate(tokens):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils.py\", line 357, in split\n",
      "    # This is a final match, we need to reset and\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "# Hyperparameters\n",
    "batch_size = 12\n",
    "max_seq_length = 512\n",
    "epochs = 3  #3\n",
    "warmup_proportion = 0.1\n",
    "weight_decay = 0.01\n",
    "doc_stride = 512\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Load dataset\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])\n",
    "\n",
    "# Start training\n",
    "training_mrc_model(model, \n",
    "                tokenizer,\n",
    "                train_ds, \n",
    "                dev_ds,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                learning_rate=learning_rate,\n",
    "                warmup_proportion=warmup_proportion,\n",
    "                max_seq_length=max_seq_length,\n",
    "                doc_stride=doc_stride, \n",
    "                weight_decay=weight_decay,\n",
    "                save_dir=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重要度分数获取\n",
    "该步为输入中每个词赋一个重要度分数，表示该词对预测的影响度。重要度分数获取共分三步。\n",
    "#### 1）加载模型和评测数据集\n",
    "更改模型以及评估数据的存储路径（MODEL_PATH和DATA_PATH），完成模型和评测数据集的加载。赛段一数据量为1855条，赛段二数据量为4366条，请确认评测数据集完整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T13:55:48.924060Z",
     "iopub.status.busy": "2022-10-27T13:55:48.923438Z",
     "iopub.status.idle": "2022-10-27T13:55:50.191353Z",
     "shell.execute_reply": "2022-10-27T13:55:50.190246Z",
     "shell.execute_reply.started": "2022-10-27T13:55:48.924014Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "from functools import partial\n",
    "from paddlenlp.datasets import load_dataset\n",
    "# Correct MODEL_PATH and DATA_PATH before executing\n",
    "MODEL_PATH = MODEL_SAVE_PATH + '/model_state.pdparams'\n",
    "DATA_PATH = 'mrc_test.txt'\n",
    "\n",
    "# Load the trained parameters\n",
    "state_dict = paddle.load(MODEL_PATH)\n",
    "model.set_dict(state_dict)\n",
    "\n",
    "# Load test data\n",
    "# global data_ds\n",
    "# data_ds = DuReader().read(DATA_PATH)\n",
    "# data = load_data(DATA_PATH)\n",
    "# print(\"Num of data:\", len(data))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2）数据预处理\n",
    "\n",
    "a) 输入格式化：将输入的两个文本组织成模型预测所需格式，如对于Ernie3.0-base模型，其输入形式为[CLS]question[SEP]context[SEP]\n",
    "\n",
    "b) 分词位置索引：计算每个分词结果对应的原文位置索引，这里的分词包括模型分词和标准分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T08:12:03.354626Z",
     "iopub.status.busy": "2022-10-11T08:12:03.353918Z",
     "iopub.status.idle": "2022-10-11T08:12:10.856297Z",
     "shell.execute_reply": "2022-10-11T08:12:10.855179Z",
     "shell.execute_reply.started": "2022-10-11T08:12:03.354580Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20038/20038 [00:00<00:00, 35325.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['爬行垫根据中间材料的不同可以分为:XPE爬行垫、EPE爬行垫、EVA爬行垫、PVC爬行垫;其中XPE爬行垫、EPE爬行垫都属于PE材料加保鲜膜复合而成,都是无异味的环保材料,但是XPE爬行垫是品质较好的爬行垫,韩国进口爬行垫都是这种爬行垫,而EPE爬行垫是国内厂家为了减低成本,使用EPE(珍珠棉)作为原料生产的一款爬行垫,该材料弹性差,易碎,开孔发泡防水性弱。EVA爬行垫、PVC爬行垫是用EVA或PVC作为原材料与保鲜膜复合的而成的爬行垫,或者把图案转印在原材料上,这两款爬行垫通常有异味,如果是图案转印的爬行垫,油墨外露容易脱落。 当时我儿子爬的时候,我们也买了垫子,但是始终有味。最后就没用了,铺的就的薄毯子让他爬。', '真实情况是160-162。她平时谎报的168是因为不离脚穿高水台恨天高(15厘米) 图1她穿着高水台恨天高和刘亦菲一样高,(刘亦菲对外报身高172)范冰冰礼服下厚厚的高水台暴露了她的心机,对比一下两者的鞋子吧 图2 穿着高水台恨天高才和刘德华谢霆锋持平,如果她真的有168,那么加上鞋高,刘和谢都要有180?明显是不可能的。所以刘德华对外报的身高174减去10-15厘米才是范冰冰的真实身高 图3,范冰冰有一次脱鞋上场,这个最说明问题了,看看她的身体比例吧。还有目测一下她手上鞋子的鞋跟有多高多厚吧,至少超过10厘米。', '防水作为目前高端手机的标配,特别是苹果也支持防水之后,国产大多数高端旗舰手机都已经支持防水。虽然我们真的不会故意把手机放入水中,但是有了防水之后,用户心里会多一重安全感。那么近日最为火热的小米6防水吗?小米6的防水级别又是多少呢? 小编查询了很多资料发现,小米6确实是防水的,但是为了保持低调,同时为了不被别人说防水等级不够,很多资料都没有标注小米是否防水。根据评测资料显示,小米6是支持IP68级的防水,是绝对能够满足日常生活中的防水需求的。']\n"
     ]
    }
   ],
   "source": [
    "# from paddlenlp.datasets import load_dataset\n",
    "from mrc_utils import*\n",
    "# Hyperparameters\n",
    "batch_size = 1\n",
    "max_seq_length = 512\n",
    "epochs = 3  #3\n",
    "warmup_proportion = 0.1\n",
    "weight_decay = 0.01\n",
    "doc_stride = 512\n",
    "learning_rate = 1e-5\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])\n",
    "dev_context=[]\n",
    "dev_question=[]\n",
    "for data in dev_ds[:3]:\n",
    "    dev_context.append(data['context'])\n",
    "    dev_question.append(data['question'])\n",
    "print(dev_context)\n",
    "dev_trans_func = partial(prepare_validation_features, \n",
    "                            max_seq_length=max_seq_length, \n",
    "                            doc_stride=doc_stride,\n",
    "                            tokenizer=tokenizer)\n",
    "dev_ds.map(dev_trans_func, batched=True, num_workers=4)\n",
    "# print(dev_ds[0])\n",
    "    # 定义BatchSampler\n",
    "\n",
    "dev_batch_sampler = paddle.io.BatchSampler(\n",
    "    dev_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dev_batchify_fn = lambda samples, fn=Dict({\n",
    "        \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "        \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\n",
    "    }): fn(samples)\n",
    "dev_data_loader = paddle.io.DataLoader(\n",
    "        dataset=dev_ds,\n",
    "        batch_sampler=dev_batch_sampler,\n",
    "        collate_fn=dev_batchify_fn,\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-10T13:48:19.468370Z",
     "iopub.status.busy": "2022-10-10T13:48:19.467195Z",
     "iopub.status.idle": "2022-10-10T13:48:27.339399Z",
     "shell.execute_reply": "2022-10-10T13:48:27.338566Z",
     "shell.execute_reply.started": "2022-10-10T13:48:19.468335Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('加上v', 1195.7999877929688), ('恨v', 1033.4662475585938), ('报n', 990.5422668457031), ('和c', 968.9105834960938), ('超过v', 921.5376586914062), ('真实d', 905.7653503417969), ('刘德华nr', 893.1786804199219), (')x', 877.47119140625), ('平时t', 849.399169921875), ('图n', 849.0646057128906), ('这个r', 821.3957214355469), ('168m', 806.4478759765625), ('水台n', 797.172119140625), ('脱鞋v', 781.5652465820312), ('高a', 756.5150146484375), ('都d', 739.8418579101562), ('身体n', 736.9400634765625), ('谢霆锋nr', 731.70849609375), ('3m', 728.1162109375), ('10m', 725.2652587890625)]\n",
      "[('加上v', 1315.3799865722658), ('恨v', 1136.8128723144532), ('报n', 1089.5964935302736), ('超过v', 1013.6914245605469), ('和c', 968.9105834960938), ('图n', 933.9710662841798), ('真实d', 905.7653503417969), ('刘德华nr', 893.1786804199219), (')x', 877.47119140625), ('水台n', 876.8893310546875), ('脱鞋v', 859.7217712402345), ('平时t', 849.399169921875), ('这个r', 821.3957214355469), ('身体n', 810.6340698242188), ('168m', 806.4478759765625), ('高a', 756.5150146484375), ('都d', 739.8418579101562), ('谎报n', 736.9897277832032), ('谢霆锋nr', 731.70849609375), ('3m', 728.1162109375)]\n"
     ]
    }
   ],
   "source": [
    "# import jieba\n",
    "import jieba.posseg as pseg\n",
    "import numpy as np\n",
    "def MSE(y,t):\n",
    "    #形参t代表训练数据（监督数据）（真实）\n",
    "    #y代表预测数据\n",
    "    return 0.5*np.sum((y-t)**2)\n",
    "\n",
    "for step, batch in enumerate(dev_data_loader, start=1):\n",
    "    if step>1:\n",
    "        break\n",
    "    # item=dev_ds[step]\n",
    "    context=dev_context[step]\n",
    "    # seg_list=jieba.cut(context,cut_all=False)\n",
    "    seg_list =pseg.cut(context)\n",
    "    ner_list=[]\n",
    "    for w in seg_list:\n",
    "        # print(w.word)\n",
    "        # print(w.flag)\n",
    "        ner_list.append(w)\n",
    "    # print(ner_list)\n",
    "    # print(dev_question[step])\n",
    "    # global_step += 1\n",
    "    input_ids, segment_ids= batch\n",
    "    real_logits = model(input_ids=input_ids, token_type_ids=segment_ids)\n",
    "    start_logits,end_logits=real_logits\n",
    "    # print(start_logits.numpy())\n",
    "    # print('\\n',end_logits)\n",
    "    input_ids=input_ids.numpy()\n",
    "    start=0\n",
    "    mse_losses={}\n",
    "    mse_losses_flag={}\n",
    "    for w in ner_list:\n",
    "        word=w.word\n",
    "        if word in[',','.','，','。','-','+','?','!']:\n",
    "            continue\n",
    "        flag=w.flag\n",
    "        change_input_ids=input_ids[0]\n",
    "        change_input_ids[start:start+len(word)]=0\n",
    "        new_input_ids=[]\n",
    "        new_input_ids.append(change_input_ids)\n",
    "        new_input_ids=paddle.to_tensor(new_input_ids)\n",
    "        change_logits=model(input_ids=new_input_ids, token_type_ids=segment_ids)\n",
    "        new_start_logits,new_end_logits=change_logits\n",
    "        # print(new_start_logits.numpy())\n",
    "        mse_loss_start=MSE(start_logits.numpy()[0],new_start_logits.numpy()[0])\n",
    "        mse_loss_end=MSE(end_logits.numpy()[0],new_end_logits.numpy()[0])\n",
    "        mse_losses[word+flag]=(mse_loss_start+mse_loss_end)/2\n",
    "        mse_losses_flag[word+flag]=(mse_loss_start+mse_loss_end)/2\n",
    "        if(flag=='n' or flag=='v'):\n",
    "            mse_losses_flag[word+flag]*=1.1\n",
    "\n",
    "    a = sorted(mse_losses.items(), key=lambda x: x[1],reverse = True)\n",
    "    print(a[:20])\n",
    "    b = sorted(mse_losses_flag.items(), key=lambda x: x[1],reverse = True)\n",
    "    print(b[:20])\n",
    "    # print('logits',logits)\n",
    "    # loss = criterion(logits, (start_positions, end_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T13:56:15.664299Z",
     "iopub.status.busy": "2022-10-27T13:56:15.663677Z",
     "iopub.status.idle": "2022-10-27T13:56:21.828289Z",
     "shell.execute_reply": "2022-10-27T13:56:21.827283Z",
     "shell.execute_reply.started": "2022-10-27T13:56:15.664261Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]地瓜不是红薯。地瓜一般生吃或者凉拌，外形是纺锤型的，有明显的瓣状结构，内里的肉是白色的，有清淡的药香味，生吃又脆又甜，常食用可以预防肝癌、胃癌，营养价值非常高。红薯是粗粮，也叫番薯山芋。它是一种属管状花目，旋花科一年生的草本植物，富含丰富的矿物质和维生素，而且非常耐饱。地瓜是红薯吗[SEP]']\n",
      "[['[CLS]', '地', '瓜', '不', '是', '红', '薯', '。', '地', '瓜', '一', '般', '生', '吃', '或', '者', '凉', '拌', '，', '外', '形', '是', '纺', '锤', '型', '的', '，', '有', '明', '显', '的', '瓣', '状', '结', '构', '，', '内', '里', '的', '肉', '是', '白', '色', '的', '，', '有', '清', '淡', '的', '药', '香', '味', '，', '生', '吃', '又', '脆', '又', '甜', '，', '常', '食', '用', '可', '以', '预', '防', '肝', '癌', '、', '胃', '癌', '，', '营', '养', '价', '值', '非', '常', '高', '。', '红', '薯', '是', '粗', '粮', '，', '也', '叫', '番', '薯', '山', '芋', '。', '它', '是', '一', '种', '属', '管', '状', '花', '目', '，', '旋', '花', '科', '一', '年', '生', '的', '草', '本', '植', '物', '，', '富', '含', '丰', '富', '的', '矿', '物', '质', '和', '维', '生', '素', '，', '而', '且', '非', '常', '耐', '饱', '。', '地', '瓜', '是', '红', '薯', '吗', '[SEP]']]\n",
      "[[(0, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 42), (42, 43), (43, 44), (44, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50), (50, 51), (51, 52), (52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 58), (58, 59), (59, 60), (60, 61), (61, 62), (62, 63), (63, 64), (64, 65), (65, 66), (66, 67), (67, 68), (68, 69), (69, 70), (70, 71), (71, 72), (72, 73), (73, 74), (74, 75), (75, 76), (76, 77), (77, 78), (78, 79), (79, 80), (80, 81), (81, 82), (82, 83), (83, 84), (84, 85), (85, 86), (86, 87), (87, 88), (88, 89), (89, 90), (90, 91), (91, 92), (92, 93), (93, 94), (94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101), (101, 102), (102, 103), (103, 104), (104, 105), (105, 106), (106, 107), (107, 108), (108, 109), (109, 110), (110, 111), (111, 112), (112, 113), (113, 114), (114, 115), (115, 116), (116, 117), (117, 118), (118, 119), (119, 120), (120, 121), (121, 122), (122, 123), (123, 124), (124, 125), (125, 126), (126, 127), (127, 128), (128, 129), (129, 130), (130, 131), (131, 132), (132, 133), (133, 134), (134, 135), (135, 136), (136, 137), (137, 138), (138, 139), (139, 140), (140, 141), (141, 142), (142, 143), (143, 144), (144, 145), (145, 146), (146, 151)]]\n",
      "[[[0, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 16], [16, 17], [17, 18], [18, 19], [19, 20], [20, 21], [21, 22], [22, 23], [23, 24], [24, 25], [25, 26], [26, 27], [27, 28], [28, 29], [29, 30], [30, 31], [31, 32], [32, 33], [33, 34], [34, 35], [35, 36], [36, 37], [37, 38], [38, 39], [39, 40], [40, 41], [41, 42], [42, 43], [43, 44], [44, 45], [45, 46], [46, 47], [47, 48], [48, 49], [49, 50], [50, 51], [51, 52], [52, 53], [53, 54], [54, 55], [55, 56], [56, 57], [57, 58], [58, 59], [59, 60], [60, 61], [61, 62], [62, 63], [63, 64], [64, 65], [65, 66], [66, 67], [67, 68], [68, 69], [69, 70], [70, 71], [71, 72], [72, 73], [73, 74], [74, 75], [75, 76], [76, 77], [77, 78], [78, 79], [79, 80], [80, 81], [81, 82], [82, 83], [83, 84], [84, 85], [85, 86], [86, 87], [87, 88], [88, 89], [89, 90], [90, 91], [91, 92], [92, 93], [93, 94], [94, 95], [95, 96], [96, 97], [97, 98], [98, 99], [99, 100], [100, 101], [101, 102], [102, 103], [103, 104], [104, 105], [105, 106], [106, 107], [107, 108], [108, 109], [109, 110], [110, 111], [111, 112], [112, 113], [113, 114], [114, 115], [115, 116], [116, 117], [117, 118], [118, 119], [119, 120], [120, 121], [121, 122], [122, 123], [123, 124], [124, 125], [125, 126], [126, 127], [127, 128], [128, 129], [129, 130], [130, 131], [131, 132], [132, 133], [133, 134], [134, 135], [135, 136], [136, 137], [137, 138], [138, 139], [139, 140], [140, 141], [141, 142], [142, 143], [143, 144], [144, 145], [145, 146], [146, 151]]]\n"
     ]
    }
   ],
   "source": [
    "from mrc_utils import *\n",
    "from paddlenlp.datasets import load_dataset\n",
    "DATA_PATH = 'mrc_interpretation_A.txt'\n",
    "data_ds = DuReader().read(DATA_PATH)\n",
    "data = load_data(DATA_PATH)\n",
    "# print(data[:1]))\n",
    "# Hyperparameters\n",
    "batch_size = 12\n",
    "max_seq_length = 512\n",
    "epochs = 3  #3\n",
    "warmup_proportion = 0.1\n",
    "weight_decay = 0.01\n",
    "doc_stride = 512\n",
    "\n",
    "# Prepare dataloader\n",
    "test_trans_func = partial(prepare_validation_features, \n",
    "                            max_seq_length=max_seq_length, \n",
    "                            doc_stride=doc_stride,\n",
    "                            tokenizer=tokenizer)\n",
    "                            \n",
    "data_ds.map(test_trans_func, batched=True, num_workers=4)\n",
    "test_batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "        data_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_batchify_fn = lambda samples, fn=Dict({\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\n",
    "}): fn(samples)\n",
    "test_data_loader = paddle.io.DataLoader(\n",
    "    dataset=data_ds,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    collate_fn=test_batchify_fn,\n",
    "    return_list=True)\n",
    "\n",
    "# Get offset maps which will be used for score alignment\n",
    "contexts, standard_split, ori_offset_maps, standard_split_offset_maps = pre_process(data, data_ds, tokenizer)\n",
    "print(contexts[:1])\n",
    "print(standard_split[:1])\n",
    "print(ori_offset_maps[:1])\n",
    "print(standard_split_offset_maps[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T09:04:02.368630Z",
     "iopub.status.busy": "2022-10-11T09:04:02.367472Z",
     "iopub.status.idle": "2022-10-11T09:04:02.373754Z",
     "shell.execute_reply": "2022-10-11T09:04:02.372971Z",
     "shell.execute_reply.started": "2022-10-11T09:04:02.368588Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1855\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3）重要度分数获取\n",
    "我们提供attention和IG两种解释方法，可根据实际实验结果选取最有效的一种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a） Attention-based Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T13:56:27.255830Z",
     "iopub.status.busy": "2022-10-27T13:56:27.255168Z",
     "iopub.status.idle": "2022-10-27T13:56:39.986045Z",
     "shell.execute_reply": "2022-10-27T13:56:39.985026Z",
     "shell.execute_reply.started": "2022-10-27T13:56:27.255787Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trustai.interpretation.token_level import AttentionInterpreter\n",
    "from utils import create_dataloader_from_scratch\n",
    "import paddle\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Init an attention interpreter and get the importance scores\n",
    "att = AttentionInterpreter(model, device=\"gpu\", predict_fn=attention_predict_fn)\n",
    "\n",
    "# Use attention interpreter to get the importance scores for all data\n",
    "interp_results = None\n",
    "for batch in test_data_loader:\n",
    "    if interp_results:\n",
    "        interp_results += att(batch)\n",
    "        # print(interp_results)\n",
    "    else:\n",
    "        interp_results = att(batch)\n",
    "\n",
    "# Trim the output to get scores only for context\n",
    "interp_results = trim_output(interp_results, data_ds, tokenizer)\n",
    "\n",
    "# Align the results back to the standard splited tokens so that it can be evaluated correctly later\n",
    "align_res = att.alignment(interp_results, contexts, standard_split, standard_split_offset_maps, ori_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T08:30:17.274311Z",
     "iopub.status.busy": "2022-10-11T08:30:17.273648Z",
     "iopub.status.idle": "2022-10-11T08:30:17.294959Z",
     "shell.execute_reply": "2022-10-11T08:30:17.293955Z",
     "shell.execute_reply.started": "2022-10-11T08:30:17.274269Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterpretResult(words=['[CLS]', '地', '瓜', '不', '是', '红', '薯', '。', '地', '瓜', '一', '般', '生', '吃', '或', '者', '凉', '拌', '，', '外', '形', '是', '纺', '锤', '型', '的', '，', '有', '明', '显', '的', '瓣', '状', '结', '构', '，', '内', '里', '的', '肉', '是', '白', '色', '的', '，', '有', '清', '淡', '的', '药', '香', '味', '，', '生', '吃', '又', '脆', '又', '甜', '，', '常', '食', '用', '可', '以', '预', '防', '肝', '癌', '、', '胃', '癌', '，', '营', '养', '价', '值', '非', '常', '高', '。', '红', '薯', '是', '粗', '粮', '，', '也', '叫', '番', '薯', '山', '芋', '。', '它', '是', '一', '种', '属', '管', '状', '花', '目', '，', '旋', '花', '科', '一', '年', '生', '的', '草', '本', '植', '物', '，', '富', '含', '丰', '富', '的', '矿', '物', '质', '和', '维', '生', '素', '，', '而', '且', '非', '常', '耐', '饱', '。', '地', '瓜', '是', '红', '薯', '吗', '[SEP]'], word_attributions=[26.672456741333008, -58.07738494873047, -64.54483795166016, -11.655533790588379, -23.530738830566406, -33.82665252685547, -39.29488754272461, -7.500601291656494, -56.386775970458984, -66.5095443725586, -77.31051635742188, -74.48218536376953, -80.50303649902344, -80.91278839111328, -77.1578140258789, -69.86212158203125, -88.6805419921875, -87.16474914550781, -51.09682846069336, -79.56904602050781, -82.26538848876953, -67.66261291503906, -85.58882904052734, -91.9704360961914, -87.6474380493164, -72.34730529785156, -69.40495300292969, -70.787841796875, -81.68314361572266, -85.27710723876953, -80.21749877929688, -93.42695617675781, -92.43116760253906, -90.18592834472656, -96.14303588867188, -66.19949340820312, -79.55653381347656, -80.49518585205078, -73.23722839355469, -87.37515258789062, -74.40069580078125, -86.96891021728516, -88.02120971679688, -81.38883209228516, -68.48487091064453, -76.55061340332031, -88.893310546875, -92.04889678955078, -80.7656478881836, -90.63497161865234, -91.16900634765625, -95.46302795410156, -72.02256774902344, -89.48639678955078, -93.03535461425781, -81.85414123535156, -90.78614807128906, -83.58494567871094, -96.93214416503906, -66.24763488769531, -69.94144439697266, -86.49354553222656, -85.08138275146484, -79.68699645996094, -75.93650817871094, -86.87537384033203, -85.18067169189453, -90.9051742553711, -93.41381072998047, -76.50401306152344, -92.61473083496094, -96.92289733886719, -74.45556640625, -86.21369171142578, -91.52531433105469, -88.31045532226562, -90.39032745361328, -80.0723876953125, -79.8641357421875, -84.41515350341797, -15.098824501037598, -48.48862075805664, -58.359962463378906, -55.740455627441406, -75.1282730102539, -76.09407806396484, -64.23226928710938, -75.9526138305664, -79.22052764892578, -97.70803833007812, -99.15925598144531, -98.17703247070312, -95.39204406738281, -38.62263488769531, -69.6332015991211, -74.98064422607422, -72.6234359741211, -75.69160461425781, -69.26239776611328, -91.9289321899414, -89.73843383789062, -85.53001403808594, -83.86351013183594, -64.2686538696289, -91.65816497802734, -89.29885864257812, -92.4617691040039, -89.87135314941406, -84.18077850341797, -91.42250061035156, -80.21810913085938, -77.09790802001953, -96.6439208984375, -89.542724609375, -93.09996795654297, -70.18439483642578, -76.5749282836914, -79.08648681640625, -78.3675765991211, -84.5400161743164, -78.76084899902344, -87.4130630493164, -87.84163665771484, -87.6888198852539, -75.16625213623047, -85.86170196533203, -87.864013671875, -89.56388092041016, -65.11278533935547, -72.17056274414062, -72.01935577392578, -73.6202163696289, -71.46812438964844, -75.10259246826172, -75.50968170166016, -6.810060501098633, -50.58053207397461, -55.94464111328125, -17.427404403686523, -34.24204635620117, -43.8976936340332, -14.679017066955566, 26.672456741333008], pred_label=array([[12],\n",
      "       [15]], dtype=int64), pred_proba=[array([1.57054712e-03, 6.30274862e-02, 1.91396874e-04, 7.10404158e-01,\n",
      "       2.40915343e-02, 1.37618840e-01, 3.88610933e-04, 2.61345180e-04,\n",
      "       7.76002463e-03, 8.00055277e-05, 2.61324603e-05, 9.93654339e-06,\n",
      "       1.25813312e-04, 1.11807385e-05, 1.24262133e-05, 7.77688274e-06,\n",
      "       6.90680681e-05, 8.46268267e-06, 1.33161202e-05, 3.34565848e-05,\n",
      "       7.13723011e-06, 1.16637439e-05, 1.31723972e-03, 1.76060184e-05,\n",
      "       7.56473264e-06, 5.68329415e-06, 9.08382754e-06, 1.02141375e-05,\n",
      "       1.61177177e-05, 6.85718669e-06, 7.01720228e-06, 2.57360989e-05,\n",
      "       6.29065380e-06, 8.64938465e-06, 4.66151869e-06, 8.68544157e-06,\n",
      "       1.05919116e-05, 5.43190390e-06, 7.46900378e-06, 1.14676914e-05,\n",
      "       8.30752015e-06, 1.96881538e-05, 5.38700169e-06, 4.83043368e-06,\n",
      "       9.70510519e-06, 9.15117926e-06, 1.99041660e-05, 7.28280429e-06,\n",
      "       6.98956501e-06, 3.48361573e-05, 6.30566365e-06, 4.68023700e-06,\n",
      "       8.59673764e-06, 2.04769894e-05, 4.90875345e-06, 1.09777302e-05,\n",
      "       9.38105040e-06, 7.21047491e-06, 6.54684300e-06, 8.59581996e-06,\n",
      "       8.01800979e-06, 7.45397574e-06, 5.01966224e-06, 8.63112473e-06,\n",
      "       6.26770088e-06, 9.44937983e-06, 6.56245174e-06, 1.25333981e-05,\n",
      "       5.67566258e-06, 6.97873566e-06, 9.34795298e-06, 4.89230706e-06,\n",
      "       8.12035614e-06, 1.25641554e-05, 5.92868082e-06, 7.54447319e-06,\n",
      "       5.44704153e-06, 9.76774390e-06, 7.02731541e-06, 5.59113414e-06,\n",
      "       3.86379288e-05, 2.58698463e-02, 1.39870652e-04, 1.81608211e-05,\n",
      "       3.69533460e-04, 1.96788988e-05, 1.03382645e-05, 1.13016322e-05,\n",
      "       9.75312105e-06, 1.05493549e-04, 6.81047095e-06, 1.87168953e-05,\n",
      "       7.64181095e-06, 1.29509490e-05, 1.01733849e-05, 8.35020546e-06,\n",
      "       1.61510452e-05, 6.67242921e-06, 1.03515540e-05, 1.69028572e-05,\n",
      "       8.66761729e-06, 6.61275453e-06, 6.31742523e-06, 8.35807714e-06,\n",
      "       2.47632706e-05, 7.63904154e-06, 6.73113891e-06, 1.91390027e-05,\n",
      "       7.71789291e-06, 4.99376392e-06, 6.70837653e-06, 1.02124623e-05,\n",
      "       4.85640203e-06, 7.92403716e-06, 3.93136406e-06, 8.39786662e-06,\n",
      "       8.99324277e-06, 6.04032357e-06, 9.19192189e-06, 6.06535832e-06,\n",
      "       6.41158840e-06, 8.67626841e-06, 6.59953685e-06, 5.55426777e-06,\n",
      "       7.18925776e-06, 9.22809159e-06, 6.63354831e-06, 4.86856061e-06,\n",
      "       1.04576757e-05, 8.40921439e-06, 5.71793589e-06, 9.28756344e-06,\n",
      "       6.90968909e-06, 1.00281441e-05, 5.15614192e-06, 2.58029941e-05,\n",
      "       6.06361823e-03, 9.58926103e-05, 1.99114764e-03, 1.30673721e-02,\n",
      "       1.13345050e-04, 4.69823921e-04, 1.57054805e-03], dtype=float32), array([2.32072105e-03, 4.96113964e-04, 5.33925183e-02, 7.03871399e-02,\n",
      "       1.57340840e-01, 2.88697216e-03, 5.55891335e-01, 4.31083463e-04,\n",
      "       1.99563015e-04, 1.63255762e-02, 1.18785092e-05, 1.92992484e-05,\n",
      "       1.79100334e-05, 8.58850690e-05, 9.48011439e-06, 1.74805209e-05,\n",
      "       1.22791607e-05, 1.01184603e-04, 1.57149625e-05, 1.02082267e-05,\n",
      "       2.13072035e-05, 9.59046338e-06, 2.45658739e-05, 7.51135958e-05,\n",
      "       4.02965379e-05, 2.12511932e-05, 1.44388878e-05, 8.80037715e-06,\n",
      "       7.25380869e-06, 1.17880045e-05, 1.06109082e-05, 9.77942273e-06,\n",
      "       1.38310797e-05, 1.10162500e-05, 2.95471054e-05, 1.41528117e-05,\n",
      "       8.13070892e-06, 1.38637770e-05, 9.91135948e-06, 1.84010933e-05,\n",
      "       9.76233332e-06, 9.30797432e-06, 1.90394203e-05, 2.10997732e-05,\n",
      "       1.41096580e-05, 8.95127232e-06, 8.02407521e-06, 1.19524857e-05,\n",
      "       1.04900091e-05, 1.08197355e-05, 1.70375224e-05, 2.77998497e-05,\n",
      "       1.34081756e-05, 9.87339718e-06, 2.56021940e-05, 7.86397777e-06,\n",
      "       1.17356203e-05, 9.97175266e-06, 2.06941368e-05, 1.38566129e-05,\n",
      "       8.86875659e-06, 1.00084708e-05, 1.45569920e-05, 8.75668411e-06,\n",
      "       1.21608973e-05, 8.40345911e-06, 1.12993903e-05, 8.04361207e-06,\n",
      "       1.43830357e-05, 9.82995243e-06, 9.07857066e-06, 2.09804257e-05,\n",
      "       1.38899150e-05, 8.44373062e-06, 1.47680521e-05, 1.00335865e-05,\n",
      "       1.45338545e-05, 8.62203433e-06, 1.19954902e-05, 1.62117067e-05,\n",
      "       3.29417489e-05, 3.41045641e-04, 6.44822568e-02, 3.29885916e-05,\n",
      "       2.09226819e-05, 9.99415526e-04, 1.58021885e-05, 8.52408903e-06,\n",
      "       1.01286114e-05, 9.97028837e-06, 3.08200324e-05, 1.04367027e-05,\n",
      "       2.62025365e-04, 1.79891031e-05, 1.40196844e-05, 1.08517497e-05,\n",
      "       9.13545773e-06, 1.17812388e-05, 7.66584708e-06, 6.95539347e-06,\n",
      "       9.25621771e-06, 1.15786052e-05, 1.70309595e-05, 8.47377123e-06,\n",
      "       6.40514008e-06, 1.21434668e-05, 2.27530672e-05, 6.49958201e-06,\n",
      "       1.12316839e-05, 1.90996907e-05, 1.16408510e-05, 1.09699540e-05,\n",
      "       2.18546338e-05, 1.32064206e-05, 7.08005027e-05, 1.32326695e-05,\n",
      "       8.98348026e-06, 1.20214654e-05, 8.39470340e-06, 1.24011749e-05,\n",
      "       1.04369619e-05, 8.76130343e-06, 1.11559539e-05, 1.32710129e-05,\n",
      "       9.83601058e-06, 8.63543937e-06, 1.10531673e-05, 1.83278880e-05,\n",
      "       1.30598210e-05, 8.90787578e-06, 1.29699592e-05, 8.17717228e-06,\n",
      "       1.09431840e-05, 7.86502005e-06, 1.52648954e-05, 5.02163748e-05,\n",
      "       1.03529012e-04, 1.37961553e-02, 1.50822208e-03, 4.92192106e-04,\n",
      "       4.98132408e-02, 8.60682514e-04, 2.32072105e-03], dtype=float32)], rationale=(3, 7, 80, 135, 141), non_rationale=(1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140), rationale_tokens=('不', '。', '。', '。', '吗'), non_rationale_tokens=('地', '瓜', '是', '红', '薯', '地', '瓜', '一', '般', '生', '吃', '或', '者', '凉', '拌', '，', '外', '形', '是', '纺', '锤', '型', '的', '，', '有', '明', '显', '的', '瓣', '状', '结', '构', '，', '内', '里', '的', '肉', '是', '白', '色', '的', '，', '有', '清', '淡', '的', '药', '香', '味', '，', '生', '吃', '又', '脆', '又', '甜', '，', '常', '食', '用', '可', '以', '预', '防', '肝', '癌', '、', '胃', '癌', '，', '营', '养', '价', '值', '非', '常', '高', '红', '薯', '是', '粗', '粮', '，', '也', '叫', '番', '薯', '山', '芋', '。', '它', '是', '一', '种', '属', '管', '状', '花', '目', '，', '旋', '花', '科', '一', '年', '生', '的', '草', '本', '植', '物', '，', '富', '含', '丰', '富', '的', '矿', '物', '质', '和', '维', '生', '素', '，', '而', '且', '非', '常', '耐', '饱', '地', '瓜', '是', '红', '薯'), rationale_pred_proba=None, non_rationale_pred_proba=None)\n"
     ]
    }
   ],
   "source": [
    "print(align_res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b）IG-based Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-10-10T14:02:36.212789Z",
     "iopub.status.busy": "2022-10-10T14:02:36.212157Z",
     "iopub.status.idle": "2022-10-10T14:04:05.683751Z",
     "shell.execute_reply": "2022-10-10T14:04:05.682527Z",
     "shell.execute_reply.started": "2022-10-10T14:02:36.212753Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "(Fatal) Operator elementwise_add raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 69.000000MB memory on GPU 0, 15.757812GB memory has been allocated and available memory is only 24.500000MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:307)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2690/145875107.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minterp_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0minterp_results\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIG_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minterp_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIG_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/external-libraries/trustai/interpretation/token_level/method/base_interpret.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/external-libraries/trustai/interpretation/token_level/method/integrated_gradients.py\u001b[0m in \u001b[0;36minterpret\u001b[0;34m(self, data, labels, steps)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mattributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_percent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ig_interpret_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             igresult = IGResult(attributions=attributions,\n\u001b[1;32m     87\u001b[0m                                 \u001b[0mpred_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/external-libraries/trustai/interpretation/token_level/method/integrated_gradients.py\u001b[0m in \u001b[0;36m_ig_interpret_instance\u001b[0;34m(self, instance, label, steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                                                                                 \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                                                                                 \u001b[0mpaddle_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaddle_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                                                                                 embedding_name=self.embedding_name)\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mtotal_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mrc_utils.py\u001b[0m in \u001b[0;36mIG_predict_fn\u001b[0;34m(inputs, label, left, right, steps, paddle_model, embedding_name)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get logits, [bs, num_c]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get logits, [bs, num_c]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/ernie/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    804\u001b[0m                                         \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                                         \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                                         attention_mask=attention_mask)\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/ernie/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, attention_mask, task_type_ids)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                            task_type_ids=task_type_ids)\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, cache)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                 output, new_cache = mod(output,\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, cache)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         out = F.linear(\n\u001b[0;32m--> 172\u001b[0;31m             x=input, weight=self.weight, bias=self.bias, name=self.name)\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/common.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(x, weight, bias, name)\u001b[0m\n\u001b[1;32m   1545\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpre_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_C_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementwise_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0mhelper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: (Fatal) Operator elementwise_add raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 69.000000MB memory on GPU 0, 15.757812GB memory has been allocated and available memory is only 24.500000MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:307)\n"
     ]
    }
   ],
   "source": [
    "from trustai.interpretation.token_level import IntGradInterpreter\n",
    "from utils import create_dataloader_from_scratch\n",
    "# Hyperparameters\n",
    "IG_STEP = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Init an IG interpreter\n",
    "ig = IntGradInterpreter(model, predict_fn=IG_predict_fn, device=\"gpu\")\n",
    "\n",
    "# Use IG interpreter to get the importance scores for all data\n",
    "interp_results = None\n",
    "for batch in test_data_loader:\n",
    "    if interp_results:\n",
    "        interp_results += ig(batch, steps=IG_STEP)\n",
    "    else:\n",
    "        interp_results = ig(batch, steps=IG_STEP)\n",
    "\n",
    "# trim the output to get scores only for context\n",
    "interp_results = trim_output(interp_results, data_ds, tokenizer)\n",
    "\n",
    "# Align the results back to the standard splited tokens so that it can be evaluated correctly later\n",
    "align_res = ig.alignment(interp_results, contexts, standard_split, standard_split_offset_maps, ori_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成用于评估的数据\n",
    "评估文件格式要求是3列数据：编号\\t预测答案\\t证据，我们提供了脚本将模型输出结果转成评估所需格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T13:58:37.827907Z",
     "iopub.status.busy": "2022-10-27T13:58:37.826745Z",
     "iopub.status.idle": "2022-10-27T13:58:37.843734Z",
     "shell.execute_reply": "2022-10-27T13:58:37.842789Z",
     "shell.execute_reply.started": "2022-10-27T13:58:37.827861Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-58.07738495 -64.54483795 -11.65553379 -23.53073883 -33.82665253\n",
      " -39.29488754  -7.50060129 -56.38677597 -66.50954437 -77.31051636\n",
      " -74.48218536 -80.5030365  -80.91278839 -77.15781403 -69.86212158\n",
      " -88.68054199 -87.16474915 -51.09682846 -79.56904602 -82.26538849\n",
      " -67.66261292 -85.58882904 -91.9704361  -87.64743805 -72.3473053\n",
      " -69.404953   -70.7878418  -81.68314362 -85.27710724 -80.21749878\n",
      " -93.42695618 -92.4311676  -90.18592834 -96.14303589 -66.19949341\n",
      " -79.55653381 -80.49518585 -73.23722839 -87.37515259 -74.4006958\n",
      " -86.96891022 -88.02120972 -81.38883209 -68.48487091 -76.5506134\n",
      " -88.89331055 -92.04889679 -80.76564789 -90.63497162 -91.16900635\n",
      " -95.46302795 -72.02256775 -89.48639679 -93.03535461 -81.85414124\n",
      " -90.78614807 -83.58494568 -96.93214417 -66.24763489 -69.9414444\n",
      " -86.49354553 -85.08138275 -79.68699646 -75.93650818 -86.87537384\n",
      " -85.18067169 -90.90517426 -93.41381073 -76.50401306 -92.61473083\n",
      " -96.92289734 -74.45556641 -86.21369171 -91.52531433 -88.31045532\n",
      " -90.39032745 -80.0723877  -79.86413574 -84.4151535  -15.0988245\n",
      " -48.48862076 -58.35996246 -55.74045563 -75.12827301 -76.09407806\n",
      " -64.23226929 -75.95261383 -79.22052765 -97.70803833 -99.15925598\n",
      " -98.17703247 -95.39204407 -38.62263489 -69.6332016  -74.98064423\n",
      " -72.62343597 -75.69160461 -69.26239777 -91.92893219 -89.73843384\n",
      " -85.53001404 -83.86351013 -64.26865387 -91.65816498 -89.29885864\n",
      " -92.4617691  -89.87135315 -84.1807785  -91.42250061 -80.21810913\n",
      " -77.09790802 -96.6439209  -89.54272461 -93.09996796 -70.18439484\n",
      " -76.57492828 -79.08648682 -78.3675766  -84.54001617 -78.760849\n",
      " -87.41306305 -87.84163666 -87.68881989 -75.16625214 -85.86170197\n",
      " -87.86401367 -89.56388092 -65.11278534 -72.17056274 -72.01935577\n",
      " -73.62021637 -71.46812439 -75.10259247 -75.5096817   -6.8100605\n",
      " -50.58053207 -55.94464111 -17.4274044  -34.24204636 -43.89769363\n",
      " -14.67901707]\n",
      "不是红薯\n",
      "[134, 6, 2, 140, 79, 137, 3, 4, 138, 92, 5, 139, 80, 135]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Re-sort the token index according to their importance scores\n",
    "def resort(index_array, importance_score):\n",
    "    res = sorted([[idx, importance_score[idx]] for idx in index_array], key=lambda x:x[1], reverse=True)\n",
    "    res = [n[0] for n in res]\n",
    "    return res\n",
    "\n",
    "# Post-prepare the result data so that it can be used for the evaluation directly\n",
    "def prepare_eval_data(data, results, paddle_model):\n",
    "    res = {}\n",
    "    idx = 0\n",
    "    step=0\n",
    "    for data_id, inter_res in zip(data, results):\n",
    "        # Split importance score vectors for query and title from inter_res.word_attributions\n",
    "        step+=1\n",
    "        if(step==2):\n",
    "            break\n",
    "        # print(data_id,'\\n\\n\\n',inter_res)\n",
    "        importance_score = np.array(inter_res.word_attributions[1:-1])\n",
    "        print(importance_score)\n",
    "        # Extract topK importance scores\n",
    "        topk = math.ceil(len(data[data_id]['sent_token'])*RATIONALE_RATIO)\n",
    "        \n",
    "        eval_data = {}        \n",
    "        eval_data['id'] = data_id\n",
    "        label = list(inter_res.pred_label)\n",
    "        # print('\\n\\n',label[0])\n",
    "        if int(label[0])>=int(label[1])+1:\n",
    "            eval_data['pred_label'] = ''\n",
    "        else:\n",
    "            eval_data['pred_label'] = ''.join(tokenizer.convert_ids_to_tokens(data_ds[idx]['input_ids'][int(label[0]):int(label[1])+1]))\n",
    "            print(eval_data['pred_label'])\n",
    "        # Find the token index of the topK importance scores\n",
    "        eval_data['rationale'] = np.argpartition(importance_score, -topk)[-topk:]\n",
    "        # Re-sort the token index according to their importance scores\n",
    "        eval_data['rationale'] = resort(eval_data['rationale'], importance_score)\n",
    "        print(eval_data['rationale'])\n",
    "        res[data_id] = eval_data\n",
    "        idx += 1\n",
    "    return res\n",
    "\n",
    "# Generate results for evaluation\n",
    "predicts = prepare_eval_data(data, align_res, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T13:58:09.956429Z",
     "iopub.status.busy": "2022-10-27T13:58:09.955803Z",
     "iopub.status.idle": "2022-10-27T13:58:09.962099Z",
     "shell.execute_reply": "2022-10-27T13:58:09.961274Z",
     "shell.execute_reply.started": "2022-10-27T13:58:09.956389Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'id': 1, 'pred_label': '不是红薯', 'rationale': [134, 6, 2, 140, 79, 137, 3, 4, 138, 92, 5, 139, 80, 135]}}\n"
     ]
    }
   ],
   "source": [
    "print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T14:20:13.002153Z",
     "iopub.status.busy": "2022-10-27T14:20:13.001168Z",
     "iopub.status.idle": "2022-10-27T14:20:25.103040Z",
     "shell.execute_reply": "2022-10-27T14:20:25.102230Z",
     "shell.execute_reply.started": "2022-10-27T14:20:13.002096Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('是', 17911358.315734863), ('红薯', 184779.06158447266), ('地瓜', 178871.92962646484), ('生', 17667.507934570312), ('吃', 17667.507934570312), ('有', 17667.507934570312), ('粗粮', 2196.8502807617188), ('叫', 2196.8502807617188), ('番薯', 2196.8502807617188), ('山芋', 2196.8502807617188), ('属', 2196.8502807617188), ('管状花', 2196.8502807617188), ('旋', 2196.8502807617188), ('富含', 2196.8502807617188), ('矿物质', 2196.8502807617188), ('凉拌', 1606.1370849609375), ('外形', 1606.1370849609375), ('纺锤', 1606.1370849609375), ('瓣状', 1606.1370849609375), ('结构', 1606.1370849609375)]\n",
      "[('是', 1791135.8315734863), ('红薯', 30796.510264078777), ('地瓜', 29811.988271077473), ('生', 4416.876983642578), ('吃', 4416.876983642578), ('有', 4416.876983642578), ('粗粮', 1098.4251403808594), ('叫', 1098.4251403808594), ('番薯', 1098.4251403808594), ('山芋', 1098.4251403808594), ('属', 1098.4251403808594), ('管状花', 1098.4251403808594), ('旋', 1098.4251403808594), ('富含', 1098.4251403808594), ('矿物质', 1098.4251403808594), ('凉拌', 803.0685424804688), ('外形', 803.0685424804688), ('纺锤', 803.0685424804688), ('瓣状', 803.0685424804688), ('结构', 803.0685424804688)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('人', 196783.05130004883), ('应当', 19501.02310180664), ('负', 19501.02310180664), ('贩卖毒品', 19501.02310180664), ('罪', 1950.102310180664), ('犯', 1772.8202819824219), ('杀人', 1772.8202819824219), ('故意伤害', 1772.8202819824219), ('致', 1772.8202819824219), ('死亡', 1772.8202819824219), ('强奸', 1772.8202819824219), ('抢劫', 1772.8202819824219), ('放火', 1772.8202819824219), ('爆炸', 1772.8202819824219), ('投放', 1772.8202819824219), ('物质', 1772.8202819824219), ('人犯', 1772.8202819824219), ('应负', 1772.8202819824219), ('、', 1240.9741973876953), ('的', 709.1281127929688)]\n",
      "[('人', 32797.175216674805), ('应当', 4875.25577545166), ('负', 4875.25577545166), ('贩卖毒品', 4875.25577545166), ('犯', 886.4101409912109), ('杀人', 886.4101409912109), ('故意伤害', 886.4101409912109), ('致', 886.4101409912109), ('死亡', 886.4101409912109), ('强奸', 886.4101409912109), ('抢劫', 886.4101409912109), ('放火', 886.4101409912109), ('爆炸', 886.4101409912109), ('投放', 886.4101409912109), ('物质', 886.4101409912109), ('人犯', 886.4101409912109), ('应负', 886.4101409912109), ('罪', 487.525577545166), ('刑法', 136.15241527557373), ('第十七条', 88.6410140991211)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:06,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('会', 2261.52446269989), ('有', 2245.594825744629), ('作用', 2245.594825744629), ('促进', 2245.594825744629), ('产生', 2086.2984561920166), ('酸性', 205.59313297271729), ('物质', 205.59313297271729), ('可能', 205.59313297271729), ('导致', 205.59313297271729), ('肌肤', 205.59313297271729), ('PH值', 205.59313297271729), ('改变', 205.59313297271729), ('释放', 205.59313297271729), ('大量', 205.59313297271729), ('烟酸', 205.59313297271729), ('皮肤', 205.59313297271729), ('刺激', 205.59313297271729), ('使用', 205.59313297271729), ('是', 205.59313297271729), ('抗', 205.59313297271729)]\n",
      "[('会', 565.3811156749725), ('有', 561.3987064361572), ('作用', 561.3987064361572), ('促进', 561.3987064361572), ('产生', 521.5746140480042), ('酸性', 102.79656648635864), ('物质', 102.79656648635864), ('可能', 102.79656648635864), ('导致', 102.79656648635864), ('肌肤', 102.79656648635864), ('PH值', 102.79656648635864), ('改变', 102.79656648635864), ('释放', 102.79656648635864), ('大量', 102.79656648635864), ('烟酸', 102.79656648635864), ('皮肤', 102.79656648635864), ('刺激', 102.79656648635864), ('使用', 102.79656648635864), ('是', 102.79656648635864), ('抗', 102.79656648635864)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:12,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "def MSE(y,t):\n",
    "    #形参t代表训练数据（监督数据）（真实）\n",
    "    #y代表预测数据\n",
    "    return 0.5*np.sum((y-t)**2)\n",
    "step=0\n",
    "# out_file1 = open('./mrc_rationale_word.txt', 'w')\n",
    "for step, batch in tqdm(enumerate(test_data_loader, start=0)):\n",
    "    if step==3:\n",
    "        break\n",
    "    data_id=data_ds[step]['example_id']\n",
    "    results=align_res[step]\n",
    "    label = list(results.pred_label)\n",
    "    if int(label[0])>=int(label[1])+1:\n",
    "        answer = ''\n",
    "    else:\n",
    "        answer= ''.join(tokenizer.convert_ids_to_tokens(data_ds[step]['input_ids'][int(label[0]):int(label[1])+1]))\n",
    "    \n",
    "    # out_file1.write(str(data_id)+'\\t'+answer+'\\t')\n",
    "    # out_file2.write(str(data_id)+'\\t'+answer+'\\t')\n",
    "    # out_file3.write(str(data_id)+'\\t'+answer+'\\t')\n",
    "    topk = math.ceil(len(data[data_id]['sent_token'])*RATIONALE_RATIO)\n",
    "    test_context=data[data_id]\n",
    "    context=test_context['context']\n",
    "    seg_list =pseg.cut(context)\n",
    "    ner_list=[]\n",
    "    for w in seg_list:\n",
    "        ner_list.append(w)\n",
    "    # print(ner_list)\n",
    "    # print(dev_question[step])\n",
    "    # global_step += 1\n",
    "    input_ids, segment_ids= batch\n",
    "    real_logits = model(input_ids=input_ids, token_type_ids=segment_ids)\n",
    "    start_logits,end_logits=real_logits\n",
    "    # print(start_logits.numpy())\n",
    "    # print('\\n',end_logits)\n",
    "    input_ids=input_ids.numpy()\n",
    "    start=0\n",
    "    mse_losses={}\n",
    "    word_len={}\n",
    "    for w in ner_list:\n",
    "        word=w.word\n",
    "        if word in[',','.','，','。','-','+','?','!']:\n",
    "            continue\n",
    "        flag=w.flag\n",
    "        change_input_ids=input_ids[0]\n",
    "        change_input_ids[start:start+len(word)]=0\n",
    "        new_input_ids=[]\n",
    "        new_input_ids.append(change_input_ids)\n",
    "        new_input_ids=paddle.to_tensor(new_input_ids)\n",
    "        change_logits=model(input_ids=new_input_ids, token_type_ids=segment_ids)\n",
    "        new_start_logits,new_end_logits=change_logits\n",
    "        mse_loss_start=MSE(start_logits.numpy()[0],new_start_logits.numpy()[0])\n",
    "        mse_loss_end=MSE(end_logits.numpy()[0],new_end_logits.numpy()[0])\n",
    "        \n",
    "        if word in word_len.keys():\n",
    "            word_len[word]+=1\n",
    "            mse_losses[word]+=(mse_loss_start+mse_loss_end)/2\n",
    "        else:\n",
    "            word_len[word]=1\n",
    "            mse_losses[word]=(mse_loss_start+mse_loss_end)/2\n",
    "        if(flag=='n' or flag=='v'):\n",
    "            mse_losses[word]*=10\n",
    "        word_len[word]+=1\n",
    "    a = sorted(mse_losses.items(), key=lambda x: x[1],reverse = True)\n",
    "    print(a[:20])\n",
    "    for k in mse_losses.keys():\n",
    "        mse_losses[k]=mse_losses[k]/word_len[k]\n",
    "    # print(word_len)\n",
    "    # print(mse_losses)\n",
    "        # if(flag=='n' or flag=='v'):\n",
    "        #     mse_losses_flag1[word]*=10\n",
    "    a = sorted(mse_losses.items(), key=lambda x: x[1],reverse = True)\n",
    "    print(a[:20])\n",
    "    b1 = sorted(mse_losses_flag1.items(), key=lambda x: x[1],reverse = True)\n",
    "\n",
    "    for idx in range(len(b1)):\n",
    "        element=b1[idx]\n",
    "        word=element[0]\n",
    "        # print(word)\n",
    "        topk-=len(word)\n",
    "        if(topk<=0):\n",
    "            break\n",
    "        out_file1.write(word+',')\n",
    "    out_file1.write('\\n')\n",
    "        for e in range(len(word)):\n",
    "            if topk<=len(b1[idx+1][0]) and e==len(word)-1:\n",
    "                out_file1.write(str(context.find(word)+e)+'\\n')\n",
    "            else:\n",
    "                out_file1.write(str(context.find(word)+e)+',')\n",
    "    \n",
    "\n",
    "out_file1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
